# COMLProcessing

## Setup

Sistema de AnÃ¡lise e ExtraÃ§Ã£o de Dados sobre Criminalidade

Este projeto implementa um pipeline de Processamento de Linguagem Natural (PLN) para analisar notÃ­cias sobre criminalidade. O sistema Ã© capaz de classificar a relevÃ¢ncia dos artigos e extrair informaÃ§Ãµes estruturadas de textos pertinentes, utilizando modelos de Machine Learning e um Modelo de Linguagem Amplo (LLM) para a extraÃ§Ã£o de dados detalhados.ğŸš€ Funcionalidades PrincipaisConexÃ£o Segura com Banco de Dados: Utiliza um tÃºnel SSH para se conectar de forma segura a um banco de dados MongoDB, onde as notÃ­cias sÃ£o armazenadas.ClassificaÃ§Ã£o de RelevÃ¢ncia: Emprega pipelines de Machine Learning (scikit-learn) para classificar automaticamente se uma notÃ­cia Ã© relevante para o tema de crime organizado.AvaliaÃ§Ã£o de Modelos: Compara diferentes tÃ©cnicas de vetorizaÃ§Ã£o, como TF-IDF e Doc2Vec, para encontrar o modelo de classificaÃ§Ã£o com melhor desempenho. Os resultados sÃ£o registrados para anÃ¡lise.ExtraÃ§Ã£o de Entidades com LLM: Usa um LLM (via Ollama) para extrair informaÃ§Ãµes detalhadas de notÃ­cias relevantes, como:Nomes de organizaÃ§Ãµes criminosasLocalizaÃ§Ã£o (paÃ­s, estado, municÃ­pio)Datas dos eventosOcorrÃªncia de conflitosApreensÃ£o de drogas e armas (incluindo tipos e quantidades)Atores envolvidos e suas relaÃ§Ãµes.SaÃ­da Estruturada: Salva os dados extraÃ­dos em um formato limpo e estruturado (arquivo .csv), pronto para anÃ¡lise e visualizaÃ§Ã£o.

ğŸ› ï¸ Tecnologias Utilizadas
Linguagem: Python 3
Banco de Dados: MongoDB
Machine Learning: scikit-learn, gensim, imbalanced-learn
LLM & PLN: langchain, ollama
UtilitÃ¡rios: PyYAML, tqdm, pandas

âš™ï¸ ConfiguraÃ§Ã£o do AmbienteSiga os passos abaixo para configurar o ambiente de desenvolvimento.PrÃ©-requisitosPython 3.8 ou superiorAcesso a uma instÃ¢ncia MongoDBOllama instalado e com um modelo LLM disponÃ­vel (ex: brunoconterato/Gemma-3-Gaia-PT-BR-4b-it)

1. Clonar o RepositÃ³riogit clone <URL_DO_SEU_REPOSITORIO>
cd <NOME_DO_PROJETO>
2. Criar e Ativar Ambiente Virtual 
Ã‰ altamente recomendado usar um ambiente virtual para isolar as dependÃªncias do projeto.# Criar o ambiente
python -m venv .venv

# Ativar no Linux/macOS
source .venv/bin/activate

# Ativar no Windows
.venv\Scripts\activate
3. Instalar DependÃªnciasInstale todas as bibliotecas necessÃ¡rias com um Ãºnico comando:pip install -r requirements.txt
4. Configurar CredenciaisCrie um arquivo config.yml na raiz do projeto. Este arquivo nÃ£o deve ser enviado para o controle de versÃ£o (jÃ¡ estÃ¡ no .gitignore). Preencha com suas credenciais:# Exemplo de config.yml
lamcad:
    server_ip: "SEU_IP_DE_SERVIDOR"
    server_port: 22
    ssh_username: "SEU_USUARIO_SSH"
    ssh_password: "SUA_SENHA_SSH"
    # ... outras configuraÃ§Ãµes de bind ...

mongodb_lamcad:
    uri: "SUA_URI_MONGODB"
    database: "NOME_DO_BANCO"
    # ... outras configuraÃ§Ãµes de coleÃ§Ã£o ...
â–¶ï¸ Como ExecutarPara iniciar o pipeline completo de busca, classificaÃ§Ã£o e extraÃ§Ã£o, execute o script main.py:python main.py
O script irÃ¡:Conectar-se ao banco de dados.Buscar notÃ­cias relevantes.Iterar sobre cada notÃ­cia, usando o LLM para extrair as caracterÃ­sticas definidas em prompt.py.Exibir uma barra de progresso durante a extraÃ§Ã£o.Salvar os resultados no arquivo caracteristicas_extraidas_ollama.csv.ğŸ“‚ Estrutura do Projeto.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ database.py         # FunÃ§Ãµes para interagir com o MongoDB via tÃºnel SSH.
â”‚   â””â”€â”€ preprocessing.py    # Scripts para preparar os dados para os modelos.
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluation.py       # LÃ³gica para avaliar e comparar os pipelines de ML.
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pipelines.py        # DefiniÃ§Ã£o dos pipelines de classificaÃ§Ã£o (TF-IDF, Doc2Vec).
â”‚   â””â”€â”€ vectorizers.py      # Wrapper customizado do Doc2Vec para compatibilidade com scikit-learn.
â”œâ”€â”€ .gitignore              # Arquivos a serem ignorados pelo Git.
â”œâ”€â”€ main.py                 # Ponto de entrada principal do projeto.
â”œâ”€â”€ prompt.py               # Define a estrutura de dados (Pydantic) e o template do prompt para o LLM.
â”œâ”€â”€ requirements.txt        # Lista de todas as dependÃªncias Python.
â””â”€â”€ README.md               # Esta documentaÃ§Ã£o.
